ğŸ§ Evaluar de Forma Fiable las Respuestas de un LLM

ğŸ¯ Objetivo

Automatizar sin errores midiendo la calidad de las respuestas de un modelo de lenguaje (LLM) con 4 criterios clave:

ğŸ”¹ Consistencia

ğŸ”¹ PrecisiÃ³n

ğŸ”¹ Relevancia

ğŸ”¹ Claridad

ğŸ§© 1. Decide el Tipo de EvaluaciÃ³n

âš–ï¸ Dos enfoques principales:

1ï¸âƒ£ Criterios propios â†’ tÃº defines cÃ³mo medir la calidad.

2ï¸âƒ£ Un LLM evalÃºa a otro LLM â†’ solo si tienes criterios claros y objetivos definidos.

ğŸ§  Â¿QuÃ© tipo de tarea tienes?

ğŸ”¸ Tarea Ãºnica â†’ Ejemplo: consultar una ley.

ğŸ”¸ Tarea recurrente â†’ Ejemplo: redactar asuntos de correos semanales.

ğŸ‘‰ En tareas recurrentes, la estabilidad del prompt es lo mÃ¡s importante.

âœ… Recomendaciones

ğŸ•µï¸ Tareas Ãºnicas: validaciÃ³n puntual + revisiÃ³n humana.
ğŸ” Tareas recurrentes: diseÃ±o sÃ³lido + pruebas repetidas + monitoreo continuo.
âš™ï¸ 2. Los 4 Criterios para Evaluar un Prompt

ğŸ§­ A. CONSISTENCIA

ğŸ“Œ Prueba el prompt 10 veces con distintos contenidos.

ğŸ“Š EvalÃºa si cubre todos los casos de uso.

ğŸ¯ Meta: alcanzar 10/10 antes de automatizar.

âš ï¸ Valida manualmente los resultados.

ğŸ’¡ MÃ¡s consistencia = menos retrabajo.

ğŸ¯ B. PRECISIÃ“N

ğŸ”¹ Secundaria en tareas creativas (cuentos, ideas).

ğŸ”¹ CrÃ­tica en anÃ¡lisis de contenido, reportes o extracciÃ³n de datos. ğŸ§ª Cada modificaciÃ³n del prompt â†’ probar con 10 ejemplos diferentes. ğŸ”„ Confirmar consistencia antes de automatizar.

ğŸ’¡ La precisiÃ³n define la confiabilidad.

ğŸ” C. RELEVANCIA

ğŸ“Œ El modelo debe enfocarse solo en lo pedido. ğŸš« Evitar informaciÃ³n irrelevante o divagaciones. ğŸ” Repite la prueba 10 veces y revisa que responda al punto exacto.

ğŸ’¡ EvalÃºa si el modelo â€œva al granoâ€.

ğŸ—£ï¸ D. CLARIDAD

ğŸ“ Respeta lÃ­mites: longitud, tono, estilo y formato. ğŸ§¾ Comprueba que mantenga coherencia visual y textual. ğŸ•’ Revisa el prompt cada semana.

âš ï¸ Los modelos cambian sin avisar (GPT-4, GPT-5, Opus, Sonnetâ€¦) ğŸ‘€ Tu tarea: vigilar, ajustar y mantener el control.

ğŸ”„ 3. ValidaciÃ³n Cruzada entre Modelos (Gemini + ChatGPT)

ğŸ’¡ Objetivo: Reducir errores y alucinaciones comparando respuestas entre LLMs.

ğŸ§± Ejemplo prÃ¡ctico: bÃºsqueda legal

Tema: Custodia de la informaciÃ³n en la Ley de Instituciones de CrÃ©dito.

ğŸ”¹ Paso 1: En Gemini

ğŸ“‚ Carga los documentos.

âš–ï¸ Indica que actÃºe como asistente legal.

ğŸ“œ Pide que responda solo con base en los archivos adjuntos.

âŒ Si no tiene datos, debe avisar. â†’ Gemini responde: â€œNo encuentra informaciÃ³nâ€.

ğŸ”¹ Paso 2: En ChatGPT

ğŸ“¥ Sube los mismos documentos.

âœï¸ Reformula sin ambigÃ¼edad:

â€œÂ¿Existe alguna ley sobre custodia de la informaciÃ³n?â€ âœ… ChatGPT confirma que sÃ­ y ubica la normativa. ğŸ“‘ Ofrece extraer los artÃ­culos relevantes.

ğŸ”¹ Paso 3: Vuelta a Gemini

ğŸ“‹ Pega la respuesta de ChatGPT.

ğŸ“– Pide que verifique la informaciÃ³n comparÃ¡ndola con los artÃ­culos 124 y 79.

ğŸ” Gemini confirma que la informaciÃ³n es correcta.

ğŸ’¬ Beneficios de la ValidaciÃ³n Cruzada

âœ¨ No depende de palabras literales.

ğŸš¨ Detecta alucinaciones o errores.

â±ï¸ Ahorra tiempo de lectura.

 ğŸ§° Complementa (no reemplaza) tÃ©cnicas de prompting restrictivas.
